{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "MB4lweuIJye5",
        "outputId": "70ea6030-c687-4b12-e9a1-280d3f6af4ea"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'geocoded_addresses.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8c51e42353b0>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moutput_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'empty_coordinates.csv'\u001b[0m  \u001b[0;31m# Output CSV file to save rows with empty coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mfind_empty_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-8c51e42353b0>\u001b[0m in \u001b[0;36mfind_empty_coordinates\u001b[0;34m(input_csv, output_csv)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_empty_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Read the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Identify rows with empty latitude or longitude fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'geocoded_addresses.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def find_empty_coordinates(input_csv, output_csv):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Identify rows with empty latitude or longitude fields\n",
        "    empty_coords_df = df[df['latitude'].isna() | df['longitude'].isna()]\n",
        "\n",
        "    # Write the rows with empty coordinates to a new CSV file\n",
        "    empty_coords_df.to_csv(output_csv, index=False)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    input_csv = 'geocoded_addresses.csv'  # Input CSV file with columns 'latitude' and 'longitude'\n",
        "    output_csv = 'empty_coordinates.csv'  # Output CSV file to save rows with empty coordinates\n",
        "\n",
        "    find_empty_coordinates(input_csv, output_csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/geocoded_ekiti_addresses_complete.csv')\n",
        "\n",
        "\n",
        "# Identify rows with empty latitude or longitude fields\n",
        "empty_coords_df = df[df['latitude'].isna() | df['longitude'].isna()]\n",
        "\n",
        "# Write the rows with empty coordinates to a new CSV file\n",
        "empty_coords_df.to_csv(output_csv, index=False)\n",
        "\n",
        "# Print the specified columns\n",
        "print(empty_coords_df[['PU-Code', 'latitude', 'longitude']].info())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNR7zy-fKHIA",
        "outputId": "54f222d7-6934-4614-b35a-741bfb92f697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 41 entries, 164 to 2121\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   PU-Code    41 non-null     object \n",
            " 1   latitude   0 non-null      float64\n",
            " 2   longitude  0 non-null      float64\n",
            "dtypes: float64(2), object(1)\n",
            "memory usage: 1.3+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def remove_empty_coordinates(input_csv, output_csv):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Identify rows with non-empty latitude and longitude fields\n",
        "    cleaned_df = df.dropna(subset=['latitude', 'longitude'])\n",
        "\n",
        "    # Write the cleaned data to a new CSV file\n",
        "    cleaned_df.to_csv(output_csv, index=False)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    input_csv = '/content/sample_data/geocoded_complete_lagos.csv'  # Input CSV file with columns 'latitude' and 'longitude'\n",
        "    output_csv = 'cleaned_geocoded_Lagos_addresses.csv'  # Output CSV file to save the cleaned data\n",
        "\n",
        "    remove_empty_coordinates(input_csv, output_csv)\n"
      ],
      "metadata": {
        "id": "lwEWYnYpKGOE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the cleaned Ekiti sheet\n",
        "\n",
        "df = pd.read_csv('/content/cleaned_geocoded_Lagos_addresses.csv')\n",
        "print(df[['latitude', 'longitude']])\n",
        "print(df[['latitude', 'longitude']].max())\n",
        "print(df[['latitude', 'longitude']].min())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pv1Mt5oOQ80",
        "outputId": "4cd65428-5fec-4839-e089-526a73926a7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      latitude  longitude\n",
            "0     6.615050   3.325020\n",
            "1     6.615050   3.325020\n",
            "2     6.615050   3.325020\n",
            "3     6.615050   3.325020\n",
            "4     6.615050   3.325020\n",
            "...        ...        ...\n",
            "7095  6.506032   3.338329\n",
            "7096  6.531099   3.352780\n",
            "7097  6.531099   3.352780\n",
            "7098  6.531099   3.352780\n",
            "7099  6.531099   3.352780\n",
            "\n",
            "[7100 rows x 2 columns]\n",
            "latitude      65.317350\n",
            "longitude    151.468845\n",
            "dtype: float64\n",
            "latitude     -40.760352\n",
            "longitude   -147.802780\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to read a CSV file and drop rows with latitude and longitude outside Nigeria's boundaries\n",
        "def clean_coordinates(input_csv, output_csv):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Define Nigeria's latitude and longitude boundaries\n",
        "    min_latitude, max_latitude = 4.27, 13.86\n",
        "    min_longitude, max_longitude = 2.67, 14.62\n",
        "\n",
        "    # Drop rows where latitude or longitude are outside the boundaries\n",
        "    cleaned_df = df[(df['latitude'].between(min_latitude, max_latitude)) &\n",
        "                    (df['longitude'].between(min_longitude, max_longitude))]\n",
        "\n",
        "    # Write the cleaned DataFrame to a new CSV file\n",
        "    cleaned_df.to_csv(output_csv, index=False)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    input_csv = '/content/sample_data/cleaned_geocoded_Lagos_addresses.csv'  # Replace with your input CSV file path\n",
        "    output_csv = '/content/sample_data/cleaned_output.csv'  # Replace with your desired output CSV file path\n",
        "\n",
        "    clean_coordinates(input_csv, output_csv)\n"
      ],
      "metadata": {
        "id": "WZYMFbHQ7qVJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/cleaned_output.csv')\n",
        "print(df[['latitude', 'longitude']])\n",
        "print(df[['latitude', 'longitude']].max())\n",
        "print(df[['latitude', 'longitude']].min())\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwZqb4xR72nY",
        "outputId": "2452088d-90ec-4470-ad79-a7ca0a3978bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      latitude  longitude\n",
            "0     6.615050   3.325020\n",
            "1     6.615050   3.325020\n",
            "2     6.615050   3.325020\n",
            "3     6.615050   3.325020\n",
            "4     6.615050   3.325020\n",
            "...        ...        ...\n",
            "6737  6.506032   3.338329\n",
            "6738  6.531099   3.352780\n",
            "6739  6.531099   3.352780\n",
            "6740  6.531099   3.352780\n",
            "6741  6.531099   3.352780\n",
            "\n",
            "[6742 rows x 2 columns]\n",
            "latitude      8.974910\n",
            "longitude    10.355441\n",
            "dtype: float64\n",
            "latitude     6.0005\n",
            "longitude    2.8000\n",
            "dtype: float64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6742 entries, 0 to 6741\n",
            "Data columns (total 22 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   State                   6742 non-null   object \n",
            " 1   LGA                     6742 non-null   object \n",
            " 2   Ward                    6742 non-null   object \n",
            " 3   PU-Code                 6742 non-null   object \n",
            " 4   PU-Name                 6742 non-null   object \n",
            " 5   Address                 6742 non-null   object \n",
            " 6   Accredited_Voters       6742 non-null   int64  \n",
            " 7   Registered_Voters       6742 non-null   int64  \n",
            " 8   Results_Found           6742 non-null   bool   \n",
            " 9   Transcription_Count     6742 non-null   int64  \n",
            " 10  Result_Sheet_Stamped    6742 non-null   bool   \n",
            " 11  Result_Sheet_Corrected  6742 non-null   bool   \n",
            " 12  Result_Sheet_Invalid    6742 non-null   bool   \n",
            " 13  Result_Sheet_Unclear    6742 non-null   bool   \n",
            " 14  Result_Sheet_Unsigned   6742 non-null   object \n",
            " 15  APC                     6742 non-null   int64  \n",
            " 16  LP                      6742 non-null   int64  \n",
            " 17  PDP                     6742 non-null   int64  \n",
            " 18  NNPP                    6742 non-null   int64  \n",
            " 19  Results_File            6742 non-null   object \n",
            " 20  latitude                6742 non-null   float64\n",
            " 21  longitude               6742 non-null   float64\n",
            "dtypes: bool(5), float64(2), int64(7), object(8)\n",
            "memory usage: 928.5+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "import time\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/cleaned_output.csv')  # Assuming columns are 'unit_id', 'latitude', 'longitude', 'party_votes'\n",
        "\n",
        "# Example structure:\n",
        "# unit_id | latitude | longitude | party_A | party_B | party_C | ...\n",
        "\n",
        "# Function to calculate distance between two coordinates\n",
        "def calculate_distance(coord1, coord2):\n",
        "    return geodesic(coord1, coord2).kilometers\n"
      ],
      "metadata": {
        "id": "nhQPa6L-8mID"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_neighbors(data, radius):\n",
        "    neighbors = {}\n",
        "    for i, row1 in data.iterrows():\n",
        "        neighbors[row1['PU-Code']] = []\n",
        "        coord1 = (row1['latitude'], row1['longitude'])\n",
        "        for j, row2 in data.iterrows():\n",
        "            if row1['PU-Code'] != row2['PU-Code']:\n",
        "                coord2 = (row2['latitude'], row2['longitude'])\n",
        "                distance = calculate_distance(coord1, coord2)\n",
        "                if distance <= radius:\n",
        "                    neighbors[row1['PU-Code']].append(row2['PU-Code'])\n",
        "    return neighbors\n",
        "\n",
        "# Define radius (in kilometers)\n",
        "radius = 1\n",
        "neighbors = find_neighbors(data, radius)\n"
      ],
      "metadata": {
        "id": "FOY8cIgu8rW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Haversine function to calculate distance between two points\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    # Earth radius in kilometers\n",
        "    R = 6371.0\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "# Function to read the CSV file and group polling units by wards\n",
        "def group_by_wards(data):\n",
        "    grouped = data.groupby('Ward')['PU-Code'].apply(list).to_dict()\n",
        "    return grouped\n",
        "\n",
        "# Function to find neighboring wards based on geographical proximity\n",
        "def find_neighboring_wards(data, radius_km):\n",
        "    neighbors = {ward: set() for ward in data['Ward'].unique()}\n",
        "\n",
        "    for i, row1 in data.iterrows():\n",
        "        ward1 = row1['ward']\n",
        "        for j, row2 in data.iterrows():\n",
        "            if i != j:\n",
        "                distance = haversine(row1['latitude'], row1['longitude'], row2['latitude'], row2['longitude'])\n",
        "                if distance <= radius_km:\n",
        "                    ward2 = row2['ward']\n",
        "                    if ward1 != ward2:\n",
        "                        neighbors[ward1].add(ward2)\n",
        "\n",
        "    # Convert sets to lists for consistency\n",
        "    neighbors = {ward: list(neigh) for ward, neigh in neighbors.items()}\n",
        "\n",
        "    return neighbors\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your dataset\n",
        "    data = pd.read_csv('polling_units.csv')  # Ensure this CSV has columns 'lga', 'ward', 'unit_id', 'latitude', 'longitude'\n",
        "\n",
        "    # Group polling units by wards\n",
        "    wards_grouped = group_by_wards(data)\n",
        "\n",
        "    # Define radius in kilometers\n",
        "    radius = 1\n",
        "\n",
        "    # Find neighboring wards\n",
        "    neighboring_wards = find_neighboring_wards(data, radius)\n",
        "\n",
        "    # Print grouped polling units by wards\n",
        "    print(\"Polling units grouped by wards:\")\n",
        "    for ward, units in wards_grouped.items():\n",
        "        print(f'Ward {ward}: {units}')\n",
        "\n",
        "    # Print neighboring wards for each ward\n",
        "    print(\"\\nNeighboring wards for each ward:\")\n",
        "    for ward, neighbors in neighboring_wards.items():\n",
        "        print(f'Ward {ward} has neighboring wards: {neighbors}')\n"
      ],
      "metadata": {
        "id": "-8dkXaY-LxiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import radians, cos, sin, sqrt, atan2\n",
        "\n",
        "# Haversine function to calculate distance between two points\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371.0  # Earth radius in kilometers\n",
        "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = sin(dlat / 2.0)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2.0)**2\n",
        "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "# Function to find neighboring polling units within a ward\n",
        "def find_neighbors_within_ward(data, radius_km):\n",
        "    neighbors = {}\n",
        "    for i, row1 in data.iterrows():\n",
        "        pu_code = row1['PU-Code']\n",
        "        neighbors[pu_code] = []\n",
        "        for j, row2 in data.iterrows():\n",
        "            if i != j:\n",
        "                distance = haversine(row1['latitude'], row1['longitude'], row2['latitude'], row2['longitude'])\n",
        "                if distance <= radius_km:\n",
        "                    neighbors[pu_code].append(row2['PU-Code'])\n",
        "    return neighbors\n",
        "\n",
        "# Function to calculate outlier scores\n",
        "def calculate_outlier_scores(data, neighbors_dict):\n",
        "    parties = ['APC', 'LP', 'PDP', 'NNPP']\n",
        "    outlier_scores = []\n",
        "    for i, row in data.iterrows():\n",
        "        pu_code = row['PU-Code']\n",
        "        neighbors = neighbors_dict[pu_code]\n",
        "        for party in parties:\n",
        "            neighbor_votes = data[data['PU-Code'].isin(neighbors)][party].mean()\n",
        "            if neighbor_votes > 0:  # Avoid division by zero\n",
        "                deviation = abs(row[party] - neighbor_votes) / neighbor_votes\n",
        "                outlier_scores.append({\n",
        "                    'PU-Code': pu_code,\n",
        "                    'Ward': row['Ward'],\n",
        "                    'Party': party,\n",
        "                    'Outlier_Score': deviation,\n",
        "                    'Neighbor_PUs': neighbors\n",
        "                })\n",
        "    return pd.DataFrame(outlier_scores)\n",
        "\n",
        "# Function to generate report\n",
        "def generate_report(outlier_scores):\n",
        "    report = outlier_scores.sort_values(by='Outlier_Score', ascending=False)\n",
        "    top_outliers = report.head(3)\n",
        "    print(\"Detailed Report:\")\n",
        "    print(report)\n",
        "    print(\"\\nTop 3 Outliers:\")\n",
        "    for i, outlier in top_outliers.iterrows():\n",
        "        print(f\"\\nPolling Unit: {outlier['PU-Code']} in Ward: {outlier['Ward']}\")\n",
        "        print(f\"Party: {outlier['Party']} - Outlier Score: {outlier['Outlier_Score']}\")\n",
        "        print(f\"Neighboring Polling Units: {outlier['Neighbor_PUs']}\")\n",
        "        print(f\"Explanation: This polling unit has a significantly different number of votes for {outlier['Party']} compared to its neighboring units.\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your dataset\n",
        "    data = pd.read_csv('/content/sample_data/cleaned_output.csv')  # Ensure this CSV has columns 'latitude', 'longitude', 'PU_Code', 'Ward', 'APC_votes', 'LP_votes', 'PDP_votes', 'NNPP_votes'\n",
        "\n",
        "    # Group the dataframe by wards\n",
        "    wards_grouped = data.groupby('Ward')\n",
        "    #wards_grouped_df = pd.DataFrame(wards_grouped)\n",
        "    #wards_grouped_dict = {ward: group for ward, group in wards_grouped}\n",
        "    #print(wards_grouped_dict)\n",
        "\n",
        "    #print(wards_grouped_df.info())\n",
        "\n",
        "    #print(\"Polling units grouped by wards:\")\n",
        "    #for ward, group in wards_grouped:\n",
        "        #print(f'Ward {ward}: {len(group)}')\n",
        "\n",
        "    all_neighbors = {}\n",
        "    for ward, group in wards_grouped:\n",
        "        neighbors = find_neighbors_within_ward(group, radius_km=1)\n",
        "        all_neighbors.update(neighbors)\n",
        "\n",
        "    # Calculate outlier scores\n",
        "    outlier_scores = calculate_outlier_scores(data, all_neighbors)\n",
        "\n",
        "    # Generate and print the report\n",
        "    generate_report(outlier_scores)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD5DjpEw8vh0",
        "outputId": "fd9d5438-a653-4ce8-dc6c-edeb4b334c3c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detailed Report:\n",
            "            PU-Code                                       Ward Party  \\\n",
            "11492  24-20-05-019                             YABA/OJUELEGBA  NNPP   \n",
            "19738  24-08-02-082                         VICTORIA ISLAND II  NNPP   \n",
            "20668  24-10-08-125                             IJAIYE/OJOKORO  NNPP   \n",
            "16571  24-04-05-107                                      AMUWO  NNPP   \n",
            "1615   24-01-10-049                        ORILE AGEGE/OKO OBA  NNPP   \n",
            "...             ...                                        ...   ...   \n",
            "25494  24-20-02-113                                      AGUDA   PDP   \n",
            "17534  24-05-04-030  APAPA IV (PELEWURA CRESCENT AND ENVIRONS)  NNPP   \n",
            "23137  24-13-06-179          IKOSI KETU/MILE 12/AGILITI/MAIDAN   APC   \n",
            "6727   24-16-11-055                         BABALOSA/IDI-ARABA  NNPP   \n",
            "6763   24-16-11-068                         BABALOSA/IDI-ARABA  NNPP   \n",
            "\n",
            "       Outlier_Score                                       Neighbor_PUs  \n",
            "11492     101.454545  [24-20-05-001, 24-20-05-002, 24-20-05-003, 24-...  \n",
            "19738      71.000000  [24-08-02-037, 24-08-02-039, 24-08-02-040, 24-...  \n",
            "20668      63.000000  [24-10-08-068, 24-10-08-069, 24-10-08-070, 24-...  \n",
            "16571      47.000000  [24-04-05-077, 24-04-05-078, 24-04-05-079, 24-...  \n",
            "1615       46.916667  [24-01-10-001, 24-01-10-002, 24-01-10-004, 24-...  \n",
            "...              ...                                                ...  \n",
            "25494       0.000000  [24-20-02-088, 24-20-02-089, 24-20-02-090, 24-...  \n",
            "17534       0.000000  [24-05-04-013, 24-05-04-014, 24-05-04-015, 24-...  \n",
            "23137       0.000000  [24-13-06-107, 24-13-06-152, 24-13-06-161, 24-...  \n",
            "6727        0.000000  [24-16-11-002, 24-16-11-003, 24-16-11-004, 24-...  \n",
            "6763        0.000000  [24-16-11-002, 24-16-11-003, 24-16-11-004, 24-...  \n",
            "\n",
            "[25627 rows x 5 columns]\n",
            "\n",
            "Top 3 Outliers:\n",
            "\n",
            "Polling Unit: 24-20-05-019 in Ward: YABA/OJUELEGBA\n",
            "Party: NNPP - Outlier Score: 101.45454545454545\n",
            "Neighboring Polling Units: ['24-20-05-001', '24-20-05-002', '24-20-05-003', '24-20-05-004', '24-20-05-005', '24-20-05-008', '24-20-05-009', '24-20-05-010', '24-20-05-011', '24-20-05-012', '24-20-05-013', '24-20-05-014', '24-20-05-015', '24-20-05-016', '24-20-05-020', '24-20-05-021', '24-20-05-022', '24-20-05-024', '24-20-05-025', '24-20-05-026', '24-20-05-027', '24-20-05-028', '24-20-05-029']\n",
            "Explanation: This polling unit has a significantly different number of votes for NNPP compared to its neighboring units.\n",
            "\n",
            "Polling Unit: 24-08-02-082 in Ward: VICTORIA ISLAND II\n",
            "Party: NNPP - Outlier Score: 71.00000000000001\n",
            "Neighboring Polling Units: ['24-08-02-037', '24-08-02-039', '24-08-02-040', '24-08-02-041', '24-08-02-042', '24-08-02-044', '24-08-02-046', '24-08-02-047', '24-08-02-048', '24-08-02-049', '24-08-02-051', '24-08-02-052', '24-08-02-053', '24-08-02-054', '24-08-02-055', '24-08-02-057', '24-08-02-059', '24-08-02-060', '24-08-02-061', '24-08-02-062', '24-08-02-063', '24-08-02-064', '24-08-02-065', '24-08-02-067', '24-08-02-068', '24-08-02-069', '24-08-02-070', '24-08-02-071', '24-08-02-072', '24-08-02-073', '24-08-02-075', '24-08-02-076', '24-08-02-078', '24-08-02-079', '24-08-02-080', '24-08-02-081', '24-08-02-083', '24-08-02-085', '24-08-02-086', '24-08-02-087', '24-08-02-089', '24-08-02-090', '24-08-02-091', '24-08-02-092', '24-08-02-093', '24-08-02-094', '24-08-02-095', '24-08-02-096']\n",
            "Explanation: This polling unit has a significantly different number of votes for NNPP compared to its neighboring units.\n",
            "\n",
            "Polling Unit: 24-10-08-125 in Ward: IJAIYE/OJOKORO\n",
            "Party: NNPP - Outlier Score: 63.0\n",
            "Neighboring Polling Units: ['24-10-08-068', '24-10-08-069', '24-10-08-070', '24-10-08-071', '24-10-08-072', '24-10-08-074', '24-10-08-075', '24-10-08-076', '24-10-08-077', '24-10-08-080', '24-10-08-081', '24-10-08-082', '24-10-08-083', '24-10-08-084', '24-10-08-085', '24-10-08-086', '24-10-08-088', '24-10-08-089', '24-10-08-090', '24-10-08-091', '24-10-08-092', '24-10-08-094', '24-10-08-095', '24-10-08-096', '24-10-08-097', '24-10-08-098', '24-10-08-099', '24-10-08-100', '24-10-08-101', '24-10-08-103', '24-10-08-105', '24-10-08-106', '24-10-08-107', '24-10-08-108', '24-10-08-109', '24-10-08-118', '24-10-08-124', '24-10-08-131', '24-10-08-134', '24-10-08-135', '24-10-08-136', '24-10-08-137', '24-10-08-138', '24-10-08-139', '24-10-08-140', '24-10-08-141', '24-10-08-142', '24-10-08-143', '24-10-08-144', '24-10-08-145', '24-10-08-146', '24-10-08-147', '24-10-08-148', '24-10-08-149', '24-10-08-150', '24-10-08-151', '24-10-08-152', '24-10-08-153', '24-10-08-154', '24-10-08-155', '24-10-08-156', '24-10-08-157', '24-10-08-158', '24-10-08-159']\n",
            "Explanation: This polling unit has a significantly different number of votes for NNPP compared to its neighboring units.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by outlier scores\n",
        "outlier_scores_sorted = outlier_scores.sort_values(by='outlier_score', ascending=False)\n",
        "\n",
        "# Top 3 outliers\n",
        "top_outliers = outlier_scores_sorted.head(3)\n",
        "\n",
        "# Reporting\n",
        "report = f\"Top 3 Outliers Report:\\n\\n\"\n",
        "for i, row in top_outliers.iterrows():\n",
        "    unit_id = row['unit_id']\n",
        "    party = row['party']\n",
        "    score = row['outlier_score']\n",
        "    neighbors = row['neighbors']\n",
        "\n",
        "    report += f\"Polling Unit: {unit_id}\\n\"\n",
        "    report += f\"Party: {party}\\n\"\n",
        "    report += f\"Outlier Score: {score:.2f}\\n\"\n",
        "    report += f\"Neighbors: {', '.join(map(str, neighbors))}\\n\"\n",
        "    report += f\"Explanation: The votes for {party} at unit {unit_id} deviate significantly from its neighbors.\\n\\n\"\n",
        "\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "lh70lDFy80c-",
        "outputId": "7a0bf16f-c51e-4160-cd48-e1b705731dfb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'outlier_score'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e4a1fb3e3aad>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sort by outlier scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutlier_scores_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutlier_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outlier_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Top 3 outliers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtop_outliers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutlier_scores_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6757\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6758\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6760\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'outlier_score'"
          ]
        }
      ]
    }
  ]
}